{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delay discounting analyis: SOLO models\n",
    "This notebooks gives an overview of using SOLO models for analysing delay discounting data. The SOLO models estimate parameters for each data file independently from the rest. Further, each datafile is processed entirely separately. This is scalable, thus useful for very large datasets. We avoid building _very_ large models with 100's or 1,000's or participants. It can still take time, but the point is we avoid both memory and computational capacity limitations.\n",
    "\n",
    "**Parameter estimation**\n",
    "\n",
    "We can do parameter estimation by creating a model instance and calling the `sample_posterior` method while providing the data.\n",
    "\n",
    "**Posterior prediction**\n",
    "\n",
    "Once we have a posterior distribution over the parameters given the data, then we can do some posterior predictive model checking by plotting the predicted discount function along with the data. This is done with the `plot_discount_functions_region` method.\n",
    "However we can also use the `df_comparison(models, data)` function in order to plot the data along with posterior predictions of mulitple methods.\n",
    "\n",
    "**Model comparison**\n",
    "\n",
    "Some qualitative or sanity-check model evaluation is done with plotting the posterior predictions (see above). However, we might also want to do some quantitative evaluation.\n",
    "\n",
    "- WAIC\n",
    "- LOO\n",
    "\n",
    "We also calculate the log loss goodness of fit metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some basic boilerplate setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file handling\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# data + modelling\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up plotting preferences\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import toolbox code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autoreload imported modules. Convenient while I'm developing the code.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models_solo import *\n",
    "from df_data import build_metadata, import_raw_data\n",
    "from model_comparison import *\n",
    "from fitting import fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "For more info on this, see the **Data preparation** notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('data/non_parametric/*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: create experiment level metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "from collections import namedtuple\n",
    "\n",
    "def parse_filename(fname):\n",
    "    \"\"\"Extract experiment meta data from a filename. Return as a named tuple \n",
    "    where the fieldname will become the column header in the experiment meta data\n",
    "    table.\"\"\"\n",
    "    path, file = os.path.split(fname)\n",
    "    initials = file.split('-')[0]\n",
    "    domain = file.split('-')[1]\n",
    "    Metadata = namedtuple('Metadata', ['filename', 'initials', 'domain'])\n",
    "    return Metadata(filename = fname, initials=initials, domain=domain)\n",
    "\n",
    "expt_data = build_metadata(files, parse_filename)\n",
    "expt_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import raw behavioural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = import_raw_data(expt_data['filename'])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter estimation + Model Comparison\n",
    "\n",
    "First we set up a list of models that we want to examine. Then we 'fit' these models (parameter estimation) then do Bayesian model comparsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Coinflip,\n",
    "          Exponential, \n",
    "          Hyperbolic,\n",
    "          HyperboloidA, \n",
    "          HyperboloidB, \n",
    "          ConstantSensitivity, \n",
    "          ExponentialPower,\n",
    "          ExponentialLog,\n",
    "          HyperbolicLog,\n",
    "          DoubleExponential,\n",
    "          BetaDelta,\n",
    "          TradeOff,\n",
    "          ITCH,\n",
    "          DRIFT]\n",
    "\n",
    "# When we do model comparison we want model names in the WAIC/LOO plots. There will be a better solution, but we currenrly implement the workaround.\n",
    "# See https://discourse.pymc.io/t/can-we-add-model-names-when-we-do-model-comparison/935/2 for more.\n",
    "MODEL_NAME_MAP = {\n",
    "    0: \"Coinflip\",\n",
    "    1: \"Exponential\",\n",
    "    2: \"Hyperbolic\",\n",
    "    3: \"Hyperboloid A\",\n",
    "    4: \"Hyperboloid B\",\n",
    "    5: \"Constant Sensitivity\",\n",
    "    6: \"Exponential Power\",\n",
    "    7: \"Exponential Log\",\n",
    "    8: \"Hyperbolic Log\",\n",
    "    9: \"Double Exponential\",\n",
    "    10: \"BetaDelta\",\n",
    "    11: \"TradeOff\",\n",
    "    12: \"ITCH\",\n",
    "    13: \"DRIFT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running 14 models on all the participants can take time. So for basic testing, we can use the code commented out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [Coinflip,\n",
    "#           Exponential, \n",
    "#           Hyperbolic]\n",
    "\n",
    "# MODEL_NAME_MAP = {\n",
    "#     0: \"Coinflip\",\n",
    "#     1: \"Exponential\",\n",
    "#     2: \"Hyperbolic\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This will take time to compute! And it will save outputs to the specified directory\n",
    "results = fit(models, raw_data, expt_data, MODEL_NAME_MAP, save_dir='temp_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results\n",
    "We should now have a series of saved plots. These are all located in the specified `save_dir` which by default equals `'temp'`. In this folder there are model comparison plots, one for each participant. There are also subfolders for each participant, which contains a series of plots for model diagnostics etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
