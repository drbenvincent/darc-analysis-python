{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delay discounting analyis: SOLO models\n",
    "This notebooks gives an overview of using SOLO models for analysing delay discounting data. The SOLO models estimate parameters for each data file independently from the rest. Further, each datafile is processed entirely separately. This is scalable, thus useful for very large datasets. We avoid building _very_ large models with 100's or 1,000's or participants. It can still take time, but the point is we avoid both memory and computational capacity limitations.\n",
    "\n",
    "**Parameter estimation**\n",
    "\n",
    "We can do parameter estimation by creating a model instance and calling the `sample_posterior` method while providing the data.\n",
    "\n",
    "**Posterior prediction**\n",
    "\n",
    "Once we have a posterior distribution over the parameters given the data, then we can do some posterior predictive model checking by plotting the predicted discount function along with the data. This is done with the `plot_discount_functions_region` method.\n",
    "However we can also use the `df_comparison(models, data)` function in order to plot the data along with posterior predictions of mulitple methods.\n",
    "\n",
    "**Model comparison**\n",
    "\n",
    "Some qualitative or sanity-check model evaluation is done with plotting the posterior predictions (see above). However, we might also want to do some quantitative evaluation.\n",
    "\n",
    "- WAIC\n",
    "- LOO\n",
    "\n",
    "We also calculate the log loss goodness of fit metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some basic boilerplate setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file handling\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# data + modelling\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up plotting preferences\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import toolbox code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autoreload imported modules. Convenient while I'm developing the code.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models_solo import *\n",
    "from df_data import build_metadata, import_raw_data\n",
    "from fitting import fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "For more info on this, see the **Data preparation** notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('data/test/*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: create experiment level metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "from collections import namedtuple\n",
    "\n",
    "def parse_filename(fname):\n",
    "    \"\"\"Extract experiment meta data from a filename. Return as a named tuple \n",
    "    where the fieldname will become the column header in the experiment meta data\n",
    "    table.\"\"\"\n",
    "    path, file = os.path.split(fname)\n",
    "    initials = file.split('-')[0]\n",
    "    domain = file.split('-')[1]\n",
    "    Metadata = namedtuple('Metadata', ['filename', 'initials', 'domain'])\n",
    "    return Metadata(filename = fname, initials=initials, domain=domain)\n",
    "\n",
    "expt_data = build_metadata(files, parse_filename)\n",
    "expt_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import raw behavioural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = import_raw_data(expt_data['filename'])\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter estimation + Model Comparison\n",
    "\n",
    "First we set up a list of models that we want to examine. Then we 'fit' these models (parameter estimation) then do Bayesian model comparsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Coinflip,\n",
    "          Exponential, \n",
    "          Hyperbolic,\n",
    "          HyperboloidA, \n",
    "          HyperboloidB, \n",
    "          ConstantSensitivity, \n",
    "          ExponentialPower,\n",
    "          ExponentialLog,\n",
    "          HyperbolicLog,\n",
    "          DoubleExponential,\n",
    "          BetaDelta,\n",
    "          TradeOff,\n",
    "          ITCH,\n",
    "          DRIFT]\n",
    "\n",
    "# When we do model comparison we want model names in the WAIC/LOO plots. There will be a better solution, but we currently implement the workaround.\n",
    "# See https://discourse.pymc.io/t/can-we-add-model-names-when-we-do-model-comparison/935/2 for more.\n",
    "MODEL_NAME_MAP = {\n",
    "    0: \"Coinflip\",\n",
    "    1: \"Exponential\",\n",
    "    2: \"Hyperbolic\",\n",
    "    3: \"Hyperboloid A\",\n",
    "    4: \"Hyperboloid B\",\n",
    "    5: \"Constant Sensitivity\",\n",
    "    6: \"Exponential Power\",\n",
    "    7: \"Exponential Log\",\n",
    "    8: \"Hyperbolic Log\",\n",
    "    9: \"Double Exponential\",\n",
    "    10: \"BetaDelta\",\n",
    "    11: \"TradeOff\",\n",
    "    12: \"ITCH\",\n",
    "    13: \"DRIFT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all these models on all the participants can take time. So for basic testing, we can use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Coinflip,\n",
    "          Exponential, \n",
    "          Hyperbolic]\n",
    "\n",
    "MODEL_NAME_MAP = {\n",
    "    0: \"Coinflip\",\n",
    "    1: \"Exponential\",\n",
    "    2: \"Hyperbolic\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the fit. Note that this will take time to compute!\n",
    "It will export various figures to the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit(models, raw_data, expt_data, MODEL_NAME_MAP, save_dir='temp_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results\n",
    "We should now have a series of saved plots. These are all located in the specified `save_dir` which by default equals `'temp'`. In this folder there are model comparison plots, one for each participant. There are also subfolders for each participant, which contains a series of plots for model diagnostics etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do now?\n",
    "The results will have been automatically saved in a `.csv` file.\n",
    "\n",
    "Currenrly, the results table is exported in 'wide-form' where each row relates to an experimental data file. Depending on your particular analysis needs, then you might need to use Pandas to rearrange the results dataframe a bit. This will vary depending on your use case, so I will not attempt to cover example situations here. But if changes are needed, you can save the results with:\n",
    "\n",
    "```python\n",
    "results.to_csv('temp_analysis/results.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can do a few things:\n",
    "\n",
    "### Analyse in an external stats package\n",
    "The data can be imported into [JASP](https://jasp-stats.org) to do some statistical analysis.\n",
    "\n",
    "### More advanced plotting\n",
    "You could do some more advanced data visualisation in Python. The [plotnine](https://github.com/has2k1/plotnine) and [ggplot](http://ggplot.yhathq.com) packages are both good Python implementations of the grammar of graphics. Or if you like ggplot2 in R, then you could just call that from Python, or just do it in an R script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
